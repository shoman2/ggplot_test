{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SNS 데이터 분석 - 그룹 나누기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 형태소 분석"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "from konlpy.tag import Twitter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 사용자 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 컨텐츠 파일(원본파일 리스트) : 2개이상 파일 동시 등록 가능\n",
    "fname_in_lst  = ['data/RawData_101.xlsx',\n",
    "                 'data/RawData_102.xlsx',\n",
    "                 'data/RawData_103.xlsx',\n",
    "                 'data/RawData_104.xlsx',\n",
    "                 'data/RawData_105.xlsx',\n",
    "                 'data/RawData_106.xlsx',\n",
    "                 'data/RawData_107.xlsx'\n",
    "                 ]\n",
    "\n",
    "# 형태소 분류된 컨텐츠 파일(결과파일 리스트) : 2개이상 파일 동시 등록 가능\n",
    "fname_out_lst = ['data/morph_101.txt',\n",
    "                 'data/morph_102.txt',\n",
    "                 'data/morph_103.txt',\n",
    "                 'data/morph_104.txt',\n",
    "                 'data/morph_105.txt',\n",
    "                 'data/morph_106.txt',\n",
    "                 'data/morph_107.txt'\n",
    "                ]\n",
    "\n",
    "# 글자수가 LEN_MAX 미만은 삭제(2글자 이상부터 처리)\n",
    "LEN_MAX = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 형태소 분류 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def morph( lines ):\n",
    "#\n",
    "# Twitter tag list for Twitter.pos(): string --> list\n",
    "#\n",
    "# 'Noun', 'ProperNoun', 'Number', 'Verb', 'Adjective', 'Modifier', 'Adverb',\n",
    "# 'Exclamation', 'Josa', 'Conjunction', 'PreEomi', 'Eomi', 'VerbPrefix',\n",
    "# 'Suffix', 'Punctuation', 'CashTag', 'Others', 'Unknown', 'Alpha', 'Foreign'\n",
    "# 'KoreanParticle'\n",
    "#\n",
    "    tw = Twitter()\n",
    "\n",
    "    res_list = []\n",
    "    for line in lines:\n",
    "        lt_word = tw.pos(line, norm=True, stem=True)\n",
    "        lt_morph = []\n",
    "        for word in lt_word:\n",
    "#            if not word[1] in ['Number', 'Punctuation', 'CashTag', 'Josa',\n",
    "#                               'Alpha', 'Foreign', 'Others', 'Unknown', 'KoreanParticle']:\n",
    "#            if word[1] in ['Noun', 'ProperNoun']:\n",
    "            if word[1] == 'Noun' and len(word[0]) >= LEN_MAX:\n",
    "                lt_morph.append(word[0])\n",
    "        v_str = (\" \".join(lt_morph)).strip()\n",
    "        res_list.append(v_str)\n",
    "    \n",
    "    return res_list\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 형태소 분류 파일 생성 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#===========================================================================\n",
    "# convert_file: xlsx file --> txt(\\t) file ( morpheme analysis )\n",
    "#===========================================================================\n",
    "def convert_file( fout, *fins ):\n",
    "\n",
    "    # Remove file\n",
    "    if os.path.exists(fout): os.remove(fout)\n",
    "\n",
    "    for fname in fins:\n",
    "        try:\n",
    "            df = pd.read_excel(fname, index_col='doc_id', keep_default_na=False, encoding='cp949')\n",
    "        except:\n",
    "            print(\"convert_file(): read_csv FAIL\")\n",
    "            continue\n",
    "\n",
    "        df.sort_index(inplace=True)\n",
    "\n",
    "        df['tmp'] = morph(list(df['content']))\n",
    "\n",
    "        try:\n",
    "            df['tmp'].to_csv(fout, mode='a', header=False, sep='\\t', encoding='utf-8')\n",
    "        except:\n",
    "            print(\"convert_file(): to_csv FAIL\")\n",
    "            continue\n",
    "    return\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 형태소 분류 파일 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "for fname_in, fname_out in zip(fname_in_lst,fname_out_lst):\n",
    "    convert_file( fname_out, fname_in )\n",
    "    print('Convert File: {} --> {}'.format(fname_in, fname_out))\n",
    "    \n",
    "    #\n",
    "    # FDNX FIXME: For testing...\n",
    "    #\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# end of file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
